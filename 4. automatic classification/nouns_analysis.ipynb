{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nouns_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPuKzsLI+LulX+sxOfOGv6P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# %cd /content/drive/My Drive/Ntu/nndl/CZ4042 Final Project\n","\n","%cd /content/drive/My Drive/CZ4034 Information Retrieval/simulate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeTxMkyGTkii","executionInfo":{"status":"ok","timestamp":1649446690559,"user_tz":-480,"elapsed":2930,"user":{"displayName":"Hussain Kheriwala","userId":"09034066497351037423"}},"outputId":"4c4c51f3-7c1c-47d2-ebd9-664a4f06d0ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1VPuFOkV6y3xuglvuLABKy8nlU6W8xStE/CZ4034 Information Retrieval/simulate\n"]}]},{"cell_type":"code","source":["!python -m spacy download en_core_web_md"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xaSMf2mNTqyQ","executionInfo":{"status":"ok","timestamp":1649446711119,"user_tz":-480,"elapsed":20563,"user":{"displayName":"Hussain Kheriwala","userId":"09034066497351037423"}},"outputId":"fdeffeed-2b62-4059-9704-422482d8d34f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_md==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n","\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.63.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_md')\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izFBWofZTPBB","executionInfo":{"status":"ok","timestamp":1649449503428,"user_tz":-480,"elapsed":28801,"user":{"displayName":"Hussain Kheriwala","userId":"09034066497351037423"}},"outputId":"4f0b7d36-f9af-48d8-b722-906e6481d2d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","import spacy \n","import en_core_web_md\n","nlp = en_core_web_md.load()\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from textblob import TextBlob\n","from nltk.tokenize import sent_tokenize, word_tokenize \n","from nltk.stem import WordNetLemmatizer \n","from nltk.corpus import stopwords\n","from collections import Counter\n","from pathlib import Path\n","from wordcloud import WordCloud\n","import warnings"]},{"cell_type":"code","source":["hotel_info_path = 'data/hotel/hotel_info.csv'\n","hotel_reviews_path = 'data/reviews/hotel_reviews.csv'\n","wordcloud_path = 'wordcloud'"],"metadata":{"id":"sanZLNXlTjVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cleans input text.\n","def text_cleaner(text):\n","    text = re.sub(r'\\W', ' ', text)\n","    text = text.lower()\n","    text = re.sub(r'^br$', ' ', text)\n","    text = re.sub(r'\\s+br\\s+',' ',text)\n","    text = re.sub(r'\\s+[a-z]\\s+', ' ',text)\n","    text = re.sub(r'^b\\s+', '', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","\n","    text_tokens = word_tokenize(text)\n","    stop_words = set(stopwords.words())\n","    tokens_without_sw = [word for word in text_tokens if not word in stop_words]\n","\n","    filtered_sentence = (\" \").join(tokens_without_sw)\n","\n","    return text\n","  \n","# Init the Wordnet Lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# function to get nouns\n","def spacy_nouns(text):\n","  sentences = sent_tokenize(text) \n","  nouns = []\n","  for sentence in sentences:\n","    #Initialise\n","    doc = nlp(sentence)\n","    for chunk in doc.noun_chunks:\n","      adjectives = []\n","      noun = \"\"\n","      for tok in chunk:\n","          if tok.pos_ == \"NOUN\":\n","              nouns.append(lemmatizer.lemmatize(tok.text.lower()))\n","  return nouns\n","\n","# similarity between words\n","def get_similarity(word1, word2):\n","    tokens = nlp('{} {}'.format(word1, word2))\n","\n","    token1, token2 = tokens[0], tokens[1]\n","    return token1.similarity(token2)\n","\n","def get_adjectives_textblob(text):\n","  blob = TextBlob(text)\n","  jj_rb_list = [ word for (word,tag) in blob.tags if tag == \"JJ\"]\n","  return jj_rb_list"],"metadata":{"id":"zAzP9MVkU9qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def nouns_analyser(hotel_info_path, hotel_reviews_path, wordcloud_path):\n","  warnings.filterwarnings(\"ignore\", message=r\"\\[W008\\]\", category=UserWarning)\n","\n","  print(\"Data preprocessing...\")\n","  # Get df\n","  df = pd.read_csv(hotel_reviews_path)\n","\n","  # Get postive negative reviews\n","  df = df[['hotel_name', 'review_pos', 'review_neg']]\n","  df_neg_reviews = df[['hotel_name', 'review_neg']].rename(columns={'review_neg':'review'}).copy()\n","  df_pos_reviews = df[['hotel_name', 'review_pos']].rename(columns={'review_pos':'review'}).copy()\n","\n","  # Drop NA\n","  df_neg_reviews.dropna(inplace = True)\n","  df_pos_reviews.dropna(inplace = True)\n","\n","  # strips white spaces from front and back of text followed by spilting words into an array\n","  df_neg_reviews['word_count'] = df_neg_reviews['review'].apply(lambda x: len(x.strip().split(' ')))\n","  df_pos_reviews['word_count'] = df_pos_reviews['review'].apply(lambda x: len(x.strip().split(' ')))\n","\n","  word_len_threshold = 5 # threshold for the minimum number of words in a sentence/document\n","  df_pos_reviews_cleaned = df_pos_reviews[df_pos_reviews['word_count'].apply(lambda x: x > word_len_threshold)] # filters sentences/\n","  df_neg_reviews_cleaned = df_neg_reviews[df_neg_reviews['word_count'].apply(lambda x: x > word_len_threshold)] # filters sentences/docs\n","\n","  # Clean text\n","  df_neg_reviews['review'] = df_neg_reviews['review'].apply(text_cleaner)\n","  df_pos_reviews['review'] = df_pos_reviews['review'].apply(text_cleaner)\n","\n","  # Create neg and pos dictionaries\n","  hotel_names_pos = df_pos_reviews_cleaned['hotel_name'].drop_duplicates().values.tolist()\n","  hotel_reviews_pos_dict = {}\n","\n","  for hotel_name in hotel_names_pos:\n","    query = df_pos_reviews_cleaned[df_pos_reviews_cleaned.hotel_name == hotel_name]\n","    reviews = query['review'].values.tolist()\n","    hotel_reviews_pos_dict[hotel_name] = reviews\n","\n","  hotel_names_neg = df_neg_reviews_cleaned['hotel_name'].drop_duplicates().values.tolist()\n","  hotel_reviews_neg_dict = {}\n","\n","  for hotel_name in hotel_names_neg:\n","    query = df_neg_reviews_cleaned[df_neg_reviews_cleaned.hotel_name == hotel_name]\n","    reviews = query['review'].values.tolist()\n","    hotel_reviews_neg_dict[hotel_name] = reviews\n","\n","  # Extract top nouns for each hotel\n","  print(\"Extracting best and worst nouns...\")\n","  top_k = 3\n","\n","  hotel_nouns_pos_dict = {}\n","  for hotel_name in hotel_names_pos:\n","    pos_reviews = hotel_reviews_pos_dict[hotel_name]\n","    top_nouns = []\n","    for review in pos_reviews:\n","      top_nouns.extend(spacy_nouns(review))\n","\n","    nouns_count = Counter(top_nouns).most_common()\n","    nouns_sorted = [i[0] for i in nouns_count]\n","    hotel_nouns_pos_dict[hotel_name] = nouns_sorted\n","\n","  hotel_nouns_neg_dict = {}\n","  for hotel_name in hotel_names_neg:\n","    neg_reviews = hotel_reviews_neg_dict[hotel_name]\n","    top_nouns = []\n","    for review in neg_reviews:\n","      top_nouns.extend(spacy_nouns(review))\n","\n","    nouns_count = Counter(top_nouns).most_common()\n","    nouns_sorted = [i[0] for i in nouns_count]\n","    hotel_nouns_neg_dict[hotel_name] = nouns_sorted\n","\n","  hotel_concat = {'hotel_name': [], 'best_noun': [], 'worst_noun': []}\n","  all_hotel_names = list(set(list(hotel_names_pos) + list(hotel_names_neg)))\n","\n","  for hotel_name in all_hotel_names:\n","    if (hotel_name in hotel_names_pos) and (hotel_name in hotel_names_neg):\n","      hotel_concat['hotel_name'].append(hotel_name)\n","      best_nouns = hotel_nouns_pos_dict[hotel_name][:top_k]\n","      neg_nouns = hotel_nouns_neg_dict[hotel_name]\n","      worst_nouns = []\n","\n","      count = top_k\n","      while count != 0:\n","        if len(neg_nouns) == 0:\n","          break\n","        if neg_nouns[0] not in best_nouns:\n","          worst_nouns.append(neg_nouns[0])\n","          count = count - 1\n","        neg_nouns = neg_nouns[1:]\n","      \n","      hotel_concat['worst_noun'].append(','.join(worst_nouns))\n","      hotel_concat['best_noun'].append(','.join(best_nouns))\n","    \n","    elif (hotel_name in hotel_names_pos):\n","      hotel_concat['hotel_name'].append(hotel_name)\n","      hotel_concat['best_noun'].append(','.join(hotel_nouns_pos_dict[hotel_name][:top_k]))\n","      hotel_concat['worst_noun'].append(' ')\n","\n","    elif (hotel_name in hotel_names_neg):\n","      hotel_concat['hotel_name'].append(hotel_name)\n","      hotel_concat['best_noun'].append(' ')\n","      hotel_concat['worst_noun'].append(','.join(hotel_nouns_neg_dict[hotel_name][:top_k]))\n","\n","  # df for best and worst nouns\n","  df_best_worst_nouns = pd.DataFrame(data=hotel_concat)\n","\n","  # Extract predefined filters for each hotel\n","  print(\"Extracting top features...\")\n","  predefined_nouns = ['room', 'facilities', 'location', 'staff', 'food']\n","  pos_nouns_count = {key:{'room': 0, 'facilities': 0, 'location': 0, 'staff': 0, 'food': 0} for (key,value) in hotel_nouns_pos_dict.items()}\n","\n","  # Extracting Adjectives for wordcloud\n","  similarity_threshold = 0.5\n","  for hotel_name, nouns in hotel_nouns_pos_dict.items():\n","    for noun in nouns:\n","      for predefined_noun in predefined_nouns:\n","        # Check if same noun\n","        if noun == predefined_noun:\n","          pos_nouns_count[hotel_name][predefined_noun] = pos_nouns_count[hotel_name][predefined_noun] + 1\n","        # If not same, compute similarity\n","        elif get_similarity(noun, predefined_noun) > similarity_threshold:\n","          pos_nouns_count[hotel_name][predefined_noun] = pos_nouns_count[hotel_name][predefined_noun] + 1\n","\n","  neg_nouns_count = {key:{'room': 0, 'facilities': 0, 'location': 0, 'staff': 0, 'food': 0} for (key,value) in hotel_nouns_neg_dict.items()}\n","\n","  for hotel_name, nouns in hotel_nouns_neg_dict.items():\n","    for noun in nouns:\n","      for predefined_noun in predefined_nouns:\n","        # Check if same noun\n","        if noun == predefined_noun:\n","          neg_nouns_count[hotel_name][predefined_noun] = neg_nouns_count[hotel_name][predefined_noun] + 1\n","        # If not same, compute similarity\n","        elif get_similarity(noun, predefined_noun) > similarity_threshold:\n","          neg_nouns_count[hotel_name][predefined_noun] = neg_nouns_count[hotel_name][predefined_noun] + 1\n","\n","  #room': 0, 'facilities': 0, 'location': 0, 'staff': 0, 'food'\n","  hotel_names_pos = pos_nouns_count.keys()\n","  hotel_names_neg = neg_nouns_count.keys()\n","\n","  hotel_concat = {'hotel_name': [], 'features_room': [], 'features_facilities': [], 'features_location': [], 'features_staff': [], 'features_food': []}\n","  all_hotel_names = list(set(list(hotel_names_pos) + list(hotel_names_neg)))\n","\n","  for hotel_name in all_hotel_names:\n","    hotel_concat['hotel_name'].append(hotel_name)\n","    if (hotel_name in hotel_names_pos) and (hotel_name in hotel_names_neg):\n","      if pos_nouns_count[hotel_name]['room'] > neg_nouns_count[hotel_name]['room']:\n","        hotel_concat['features_room'].append(1)\n","      else:\n","        hotel_concat['features_room'].append(0)\n","\n","      if pos_nouns_count[hotel_name]['facilities'] > neg_nouns_count[hotel_name]['facilities']:\n","        hotel_concat['features_facilities'].append(1)\n","      else:\n","        hotel_concat['features_facilities'].append(0)\n","\n","      if pos_nouns_count[hotel_name]['location'] > neg_nouns_count[hotel_name]['location']:\n","        hotel_concat['features_location'].append(1)\n","      else:\n","        hotel_concat['features_location'].append(0)\n","\n","      if pos_nouns_count[hotel_name]['staff'] > neg_nouns_count[hotel_name]['staff']:\n","        hotel_concat['features_staff'].append(1)\n","      else:\n","        hotel_concat['features_staff'].append(0)\n","\n","      if pos_nouns_count[hotel_name]['food'] > neg_nouns_count[hotel_name]['food']:\n","        hotel_concat['features_food'].append(1)\n","      else:\n","        hotel_concat['features_food'].append(0)\n","    \n","    elif (hotel_name in hotel_names_pos):\n","      hotel_concat['features_room'].append(1)\n","      hotel_concat['features_facilities'].append(1)\n","      hotel_concat['features_location'].append(1)\n","      hotel_concat['features_staff'].append(1)\n","      hotel_concat['features_food'].append(1)\n","\n","\n","    elif (hotel_name in hotel_names_neg):\n","      hotel_concat['features_room'].append(0)\n","      hotel_concat['features_facilities'].append(0)\n","      hotel_concat['features_location'].append(0)\n","      hotel_concat['features_staff'].append(0)\n","      hotel_concat['features_food'].append(0)\n","\n","  # df for predefined filters\n","  df_predefined_filters = pd.DataFrame(data=hotel_concat)\n","\n","  # Change hotel info file\n","  df_hotel_info = pd.read_csv(hotel_info_path)\n","  df_hotel_info = df_hotel_info.join(df_best_worst_nouns.set_index('hotel_name'), on='hotel_name').reset_index(drop=True)\n","\n","  df_hotel_info = df_hotel_info.join(df_predefined_filters.set_index('hotel_name'), on='hotel_name').reset_index(drop=True)\n","  df_hotel_info.to_csv(hotel_info_path, index=False)\n","\n","  # Generate word cloud\n","  df_reviews = pd.concat([df_neg_reviews, df_pos_reviews])\n","\n","  df_reviews = df_reviews[['hotel_name', 'review']]\n","  hotel_names = df_reviews['hotel_name'].drop_duplicates().values.tolist()\n","\n","  # Create Directories\n","  print(\"Creating wordcloud directories...\")\n","  for hotel in hotel_names:\n","    hotel = hotel.replace('/','')\n","    hotel = hotel.replace(':', '')\n","    Path('{}/{}'.format(wordcloud_path, hotel)).mkdir(parents=True, exist_ok=True)\n","    \n","  # Extracting Adjectives for wordcloud\n","  similarity_threshold = 0.5\n","  hotel_reviews_adj_dict = {key:{'room': [], 'facilities': [], 'location': [], 'staff': [], 'food': []} for key in hotel_names}\n","  predefined_nouns = ['room', 'facilities', 'location', 'staff', 'food']\n","  for hotel_name in hotel_names:\n","    query = df_reviews[df_reviews.hotel_name == hotel_name]\n","    reviews = query['review'].values.tolist()\n","    for review in reviews:\n","      words = review.split(' ')\n","      for predefined_noun in predefined_nouns:\n","        for word in words:\n","          # Check if same noun\n","          try:\n","            if (word == predefined_noun) or (get_similarity(word, predefined_noun) > similarity_threshold):\n","\n","              # Add only the adjectives\n","              hotel_reviews_adj_dict[hotel_name][predefined_noun].append(' '.join(get_adjectives_textblob(review)))\n","              break\n","          except:\n","            continue\n","\n","  print(\"Generating wordclouds...\")\n","  for hotel_name, predefined_dict in hotel_reviews_adj_dict.items():\n","    for noun in predefined_nouns:\n","      text = ' '.join(predefined_dict[noun])\n","\n","      if len(text) > 0:\n","        # Create and generate a word cloud image:\n","        wordcloud = WordCloud().generate(text)\n","\n","        wordcloud.to_file('{}/{}/{}.png'.format(wordcloud_path, hotel_name, noun))\n","\n","  print(\"Done!\")\n","  return"],"metadata":{"id":"WEzECRrNU5gD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nouns_analyser(hotel_info_path, hotel_reviews_path, wordcloud_path)"],"metadata":{"id":"lbBhhsWc4gvg"},"execution_count":null,"outputs":[]}]}